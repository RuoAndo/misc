  1: # coding: utf-8
  2: 
  3: # **[DNE-01]** モジュールをインポートして、乱数のシードを設定します。
  4: 
  5: # In[1]:
  6: 
  7: 
  8: import tensorflow as tf
  9: import numpy as np
 10: import matplotlib.pyplot as plt
 11: from numpy.random import multivariate_normal, permutation
 12: import pandas as pd
 13: from pandas import DataFrame, Series
 14: 
 15: np.random.seed(20160615)
 16: tf.set_random_seed(20160615)
 17: 
 18: 
 19: # **[DNE-02]** トレーニングセットのデータを生成します。
 20: 
 21: # In[2]:
 22: 
 23: 
 24: def generate_datablock(n, mu, var, t):
 25:     data = multivariate_normal(mu, np.eye(2)*var, n)
 26:     df = DataFrame(data, columns=['x1','x2'])
 27:     df['t'] = t
 28:     return df
 29: 
 30: df0 = generate_datablock(30, [-7,-7], 18, 1)
 31: df1 = generate_datablock(30, [-7,7], 18, 0)
 32: df2 = generate_datablock(30, [7,-7], 18, 0)
 33: df3 = generate_datablock(30, [7,7], 18, 1)
 34: 
 35: df = pd.concat([df0, df1, df2, df3], ignore_index=True)
 36: train_set = df.reindex(permutation(df.index)).reset_index(drop=True)
 37: 
 38: 
 39: # **[DNE-03]** (x1, x2) と t を別々に集めたものをNumPyのarrayオブジェクトとして取り出しておきます。
 40: 
 41: # In[3]:
 42: 
 43: 
 44: train_x = train_set[['x1','x2']].as_matrix()
 45: train_t = train_set['t'].as_matrix().reshape([len(train_set), 1])
 46: 
 47: 
 48: # **[DNE-04]** 二層ネットワークによる二項分類器のモデルを定義します。
 49: 
 50: # In[4]:
 51: 
 52: 
 53: num_units1 = 2
 54: num_units2 = 2
 55: 
 56: x = tf.placeholder(tf.float32, [None, 2])
 57: 
 58: w1 = tf.Variable(tf.truncated_normal([2, num_units1]))
 59: b1 = tf.Variable(tf.zeros([num_units1]))
 60: hidden1 = tf.nn.tanh(tf.matmul(x, w1) + b1)
 61: 
 62: w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]))
 63: b2 = tf.Variable(tf.zeros([num_units2]))
 64: hidden2 = tf.nn.tanh(tf.matmul(hidden1, w2) + b2)
 65: 
 66: w0 = tf.Variable(tf.zeros([num_units2, 1]))
 67: b0 = tf.Variable(tf.zeros([1]))
 68: p = tf.nn.sigmoid(tf.matmul(hidden2, w0) + b0)
 69: 
 70: 
 71: # **[DNE-05]** 誤差関数 loss、トレーニングアルゴリズム train_step、正解率 accuracy を定義します。
 72: 
 73: # In[5]:
 74: 
 75: 
 76: t = tf.placeholder(tf.float32, [None, 1])
 77: loss = -tf.reduce_sum(t*tf.log(p) + (1-t)*tf.log(1-p))
 78: train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)
 79: correct_prediction = tf.equal(tf.sign(p-0.5), tf.sign(t-0.5))
 80: accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
 81: 
 82: 
 83: # **[DNE-06]** セッションを用意して、Variableを初期化します。
 84: 
 85: # In[6]:
 86: 
 87: 
 88: sess = tf.Session()
 89: sess.run(tf.initialize_all_variables())
 90: 
 91: 
 92: # **[DNE-07]** パラメーターの最適化を2000回繰り返します。
 93: 
 94: # In[7]:
 95: 
 96: 
 97: i = 0
 98: for _ in range(2000):
 99:     i += 1
100:     sess.run(train_step, feed_dict={x:train_x, t:train_t})
101:     if i % 100 == 0:
102:         loss_val, acc_val = sess.run(
103:             [loss, accuracy], feed_dict={x:train_x, t:train_t})
104:         print ('Step: %d, Loss: %f, Accuracy: %f'
105:                % (i, loss_val, acc_val))
106: 
107: 
108: # **[DNE-08]** 得られた確率を色の濃淡で図示します。
109: 
110: # In[8]:
111: 
112: 
113: train_set1 = train_set[train_set['t']==1]
114: train_set2 = train_set[train_set['t']==0]
115: 
116: fig = plt.figure(figsize=(6,6))
117: subplot = fig.add_subplot(1,1,1)
118: subplot.set_ylim([-15,15])
119: subplot.set_xlim([-15,15])
120: subplot.scatter(train_set1.x1, train_set1.x2, marker='x')
121: subplot.scatter(train_set2.x1, train_set2.x2, marker='o')
122: 
123: locations = []
124: for x2 in np.linspace(-15,15,100):
125:     for x1 in np.linspace(-15,15,100):
126:         locations.append((x1,x2))
127: p_vals = sess.run(p, feed_dict={x:locations})
128: p_vals = p_vals.reshape((100,100))
129: subplot.imshow(p_vals, origin='lower', extent=(-15,15,-15,15),
130:                cmap=plt.cm.gray_r, alpha=0.5)
