  1: # coding: utf-8
  2: 
  3: # **[MLE-01]** モジュールをインポートします。
  4: 
  5: # In[1]:
  6: 
  7: 
  8: import tensorflow as tf
  9: import numpy as np
 10: import matplotlib.pyplot as plt
 11: from numpy.random import multivariate_normal, permutation
 12: import pandas as pd
 13: from pandas import DataFrame, Series
 14: 
 15: 
 16: # **[MLE-02]** トレーニングセットのデータを用意します。
 17: 
 18: # In[2]:
 19: 
 20: 
 21: np.random.seed(20160512)
 22: 
 23: n0, mu0, variance0 = 20, [10, 11], 20
 24: data0 = multivariate_normal(mu0, np.eye(2)*variance0 ,n0)
 25: df0 = DataFrame(data0, columns=['x1','x2'])
 26: df0['t'] = 0
 27: 
 28: n1, mu1, variance1 = 15, [18, 20], 22
 29: data1 = multivariate_normal(mu1, np.eye(2)*variance1 ,n1)
 30: df1 = DataFrame(data1, columns=['x1','x2'])
 31: df1['t'] = 1
 32: 
 33: df = pd.concat([df0, df1], ignore_index=True)
 34: train_set = df.reindex(permutation(df.index)).reset_index(drop=True)
 35: 
 36: 
 37: # **[MLE-03]** トレーニングセットのデータの内容を確認します。
 38: 
 39: # In[3]:
 40: 
 41: 
 42: train_set
 43: 
 44: 
 45: # **[MLE-04]** (x1, x2) と t を別々に集めたものをNumPyのarrayオブジェクトとして取り出しておきます。
 46: 
 47: # In[4]:
 48: 
 49: 
 50: train_x = train_set[['x1','x2']].as_matrix()
 51: train_t = train_set['t'].as_matrix().reshape([len(train_set), 1])
 52: 
 53: 
 54: # **[MLE-05]** トレーニングセットのデータについて、t=1 である確率を求める計算式 p を用意します。
 55: 
 56: # In[5]:
 57: 
 58: 
 59: x = tf.placeholder(tf.float32, [None, 2])
 60: w = tf.Variable(tf.zeros([2, 1]))
 61: w0 = tf.Variable(tf.zeros([1]))
 62: f = tf.matmul(x, w) + w0
 63: p = tf.sigmoid(f)
 64: 
 65: 
 66: # **[MLE-06]** 誤差関数 loss とトレーニングアルゴリズム train_step を定義します。
 67: 
 68: # In[6]:
 69: 
 70: 
 71: t = tf.placeholder(tf.float32, [None, 1])
 72: loss = -tf.reduce_sum(t*tf.log(p) + (1-t)*tf.log(1-p))
 73: train_step = tf.train.AdamOptimizer().minimize(loss)
 74: 
 75: 
 76: # **[MLE-07]** 正解率 accuracy を定義します。
 77: 
 78: # In[7]:
 79: 
 80: 
 81: correct_prediction = tf.equal(tf.sign(p-0.5), tf.sign(t-0.5))
 82: accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
 83: 
 84: 
 85: # **[MLE-08]** セッションを用意して、Variableを初期化します。
 86: 
 87: # In[8]:
 88: 
 89: 
 90: sess = tf.Session()
 91: sess.run(tf.initialize_all_variables())
 92: 
 93: 
 94: # **[MLE-09]** 勾配降下法によるパラメーターの最適化を20000回繰り返します。
 95: 
 96: # In[9]:
 97: 
 98: 
 99: i = 0
100: for _ in range(20000):
101:     i += 1
102:     sess.run(train_step, feed_dict={x:train_x, t:train_t})
103:     if i % 2000 == 0:
104:         loss_val, acc_val = sess.run(
105:             [loss, accuracy], feed_dict={x:train_x, t:train_t})
106:         print ('Step: %d, Loss: %f, Accuracy: %f'
107:                % (i, loss_val, acc_val))
108: 
109: 
110: # **[MLE-10]** この時点のパラメーターの値を取り出します。
111: 
112: # In[10]:
113: 
114: 
115: w0_val, w_val = sess.run([w0, w])
116: w0_val, w1_val, w2_val = w0_val[0], w_val[0][0], w_val[1][0]
117: print(w0_val, w1_val, w2_val)
118: 
119: 
120: # **[MLE-11]** 取り出したパラメーターの値を用いて、結果をグラフに表示します。
121: 
122: # In[11]:
123: 
124: 
125: train_set0 = train_set[train_set['t']==0]
126: train_set1 = train_set[train_set['t']==1]
127: 
128: fig = plt.figure(figsize=(6,6))
129: subplot = fig.add_subplot(1,1,1)
130: subplot.set_ylim([0,30])
131: subplot.set_xlim([0,30])
132: subplot.scatter(train_set1.x1, train_set1.x2, marker='x')
133: subplot.scatter(train_set0.x1, train_set0.x2, marker='o')
134: 
135: linex = np.linspace(0,30,10)
136: liney = - (w1_val*linex/w2_val + w0_val/w2_val)
137: subplot.plot(linex, liney)
138: 
139: field = [[(1 / (1 + np.exp(-(w0_val + w1_val*x1 + w2_val*x2))))
140:           for x1 in np.linspace(0,30,100)]
141:          for x2 in np.linspace(0,30,100)]
142: subplot.imshow(field, origin='lower', extent=(0,30,0,30),
143:                cmap=plt.cm.gray_r, alpha=0.5)